# -*- coding: utf-8 -*-
"""SAR‑anomaly detection- DINO_V2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BbLhQubZ68JfRDMmaPX-Wh-JDOsvUyKr
"""

# --- SOTA DINOv2 + Mahalanobis Anomaly Detection Script ---

import random
import torch
import numpy as np
from pathlib import Path
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms as T
from transformers import AutoImageProcessor, AutoModel
import matplotlib.pyplot as plt

# 1. GLOBAL SETTINGS
BATCH_SIZE = 8                  # Batch size for processing images
PADIM_DIM = 96                  # Number of feature dimensions to select for Mahalanobis distance
SEED = 42                      # Fixed seed for reproducibility
random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available, else CPU

# 2. LOAD PATCH FILES
raw = Path('data/raw')          # Directory containing image patches
files = sorted(raw.glob('*.png'))  # Load all PNG image patches
assert len(files) >= 2, "Not enough .png patches found in data/raw"
split = int(0.7 * len(files))   # 70% train, 30% test split
train_files, test_files = files[:split], files[split:]
print(f"Train patches: {len(train_files)}, Test patches: {len(test_files)}")

# 3. PREPROCESSING
processor = AutoImageProcessor.from_pretrained("facebook/dinov2-base")  # Load DINOv2 image processor
cfg = processor.size

# Determine image size for resizing based on processor config
if isinstance(cfg, dict):
    H = cfg.get("height", cfg.get("shortest_edge"))
    W = cfg.get("width",  cfg.get("shortest_edge"))
elif isinstance(cfg, (list, tuple)):
    H, W = cfg
else:
    H = W = cfg

mean, std = processor.image_mean, processor.image_std

# Define image transforms: resize, convert to tensor, normalize
transform = T.Compose([
    T.Resize((H, W)),
    T.ToTensor(),
    T.Normalize(mean, std)
])

# 4. DATASET DEFINITION
class PatchDataset(Dataset):
    def __init__(self, file_list):
        self.file_list = file_list  # List of image file paths

    def __len__(self):
        return len(self.file_list)  # Number of image patches

    def __getitem__(self, idx):
        # Load image and convert to RGB
        im = Image.open(self.file_list[idx]).convert("RGB") #pading
        im_t = transform(im)  # Apply preprocessing transforms
        # Convert image to tensor format expected by DINOv2 processor
        pixel = processor(images=T.ToPILImage()(im_t), return_tensors="pt").pixel_values[0]
        return pixel, str(self.file_list[idx])

# Create DataLoaders for training and testing datasets
train_dl = DataLoader(PatchDataset(train_files), batch_size=BATCH_SIZE, shuffle=True)
test_dl  = DataLoader(PatchDataset(test_files),  batch_size=1, shuffle=False)

# 5. LOAD PRETRAINED DINOv2 MODEL
model = AutoModel.from_pretrained("facebook/dinov2-base").to(device).eval()
print("Loaded DINOv2-base model.")

# 6. FEATURE EXTRACTION ON TRAIN PATCHES (NORMAL DATA)
features = []
with torch.no_grad():  # Disable gradient calculation for inference speed and memory
    for pixels, _ in train_dl:
        # Forward pass through model to extract last hidden state
        # Take CLS token embedding (index 0) as patch-level feature vector
        f = model(pixel_values=pixels.to(device)).last_hidden_state[:,0,:].cpu().numpy()
        features.append(f)

# Combine all extracted features into a single numpy array
features = np.vstack(features)
print(f"Extracted features from {features.shape[0]} train patches.")

# 7. FIT MAHALANOBIS MODEL (PaDiM) USING FEATURE SUBSET
# Select a random subset of PADIM_DIM feature indices for dimensionality reduction
sel = np.random.choice(features.shape[1], PADIM_DIM, replace=False)

# Calculate the mean vector of the selected features across training patches
mu = features[:, sel].mean(axis=0)

# Calculate covariance matrix of selected features (rowvar=False means columns are variables)
cov = np.cov(features[:, sel], rowvar=False)

# Add a small diagonal matrix to covariance for numerical stability
cov += np.eye(PADIM_DIM) * 1e-6

# Compute inverse covariance matrix used as weights in Mahalanobis distance
icov = np.linalg.inv(cov)

# Function to calculate Mahalanobis distance anomaly score for a feature vector
def mahalanobis_score(f_vec):
    diff = f_vec[sel] - mu   # Difference from mean in selected feature space
    return float(diff @ icov @ diff)  # Weighted quadratic form (Mahalanobis distance)

# 8. SCORE TEST PATCHES FOR ANOMALY DETECTION
patch_scores, file_names = [], []

with torch.no_grad():
    for pixels, fname in test_dl:
        # Extract feature vector from test patch (CLS token)
        feat = model(pixel_values=pixels.to(device)).last_hidden_state[:,0,:].cpu().numpy()[0]

        # Compute Mahalanobis anomaly score
        score = mahalanobis_score(feat)

        patch_scores.append(score)
        file_names.append(fname[0])

# Convert list of scores to numpy array for easier processing
patch_scores = np.array(patch_scores)

# 9. VISUALIZATION: HISTOGRAM AND TOP ANOMALOUS PATCHES
plt.figure(figsize=(10,5))
plt.hist(patch_scores, bins=40, alpha=0.7, color='navy')
plt.xlabel("Mahalanobis Anomaly Score")
plt.ylabel("Number of Patches")
plt.title("Distribution of Test Patch Anomaly Scores")
plt.show()

# Identify indices of top 12 patches with highest anomaly scores
topk = np.argsort(patch_scores)[-12:][::-1]

# Plot top 12 anomalous patches with their scores
fig, axs = plt.subplots(3, 4, figsize=(12,8))
for ax, idx in zip(axs.flat, topk):
    im = Image.open(file_names[idx])
    ax.imshow(im)
    ax.set_title(f"Score={patch_scores[idx]:.2f}")
    ax.axis("off")

plt.suptitle("Top 12 Most Anomalous Test Patches")
plt.tight_layout()
plt.show()

print("✔️ End-to-end DINOv2 + Mahalanobis anomaly detection complete!")